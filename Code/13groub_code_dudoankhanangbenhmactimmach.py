# -*- coding: utf-8 -*-
"""13GROUB_Code_DuDoanKhaNangBenhMacTimMach.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZjpVyb6-GNqHZ8nDgkcE7htFZIFbraOE
"""

#đọc file
import pandas as pd
df=pd.read_csv('heart.csv')
#hiện 10 dòng
df.head(10)

"""Mô tả dữ liệu


*   age: Tuổi của người đó tính theo năm

*   sex: giới tính của một người (1=nam, 0= nữ)
*   cp:đau ngực đã trải qua(giá trị 1: đau thắt ngực điển hình, giá trị 2: đau không điển hình, Gía trị 3: đau không đau thắt ngực, Giá trị 4: không có triệu chứng)


*   trestbps: Huyết áp lúc nghỉ của người đó(mm Hg)




*   chol:Phép đo cholesterol của người đó tính bằng mg/dl

*   restecg: Đo điện tâm đồ khi nghỉ (0=bình thường,1=có bất thường sóng ST-T,2=hiện thị phì đại thất trái có thể xảy ra hoặc xác định theo tiêu chí của Estes)

*   thalach: Nhịp tim tối đa của người đó đạt được
*   exang: Đau thắt ngực do tập thể dục(1=có;0= không)


*   slope: Độ dốc của đoạn ST bài tập đỉnh cao (Gía trị 1: dốc lên, Gía trị 2: bằng phẳng, Gía trị 3:dốc xuống)


*  ca:Số lượng tàu chính(0-3)



*   thal: Một rối loạn về máu được gọi là thalassemia(3=bình thường;6=khiếm khuyết cố định;7=khiếm khuyết có thể phục hồi)
*   taget:Bệnh tim(0=không,1=có)

Tiến hành phân tích các thuộc tính của bộ dữ liệu
"""

#thông tin về số dòng và số cột của bộ dữ liệu
print("Số dòng của bộ dữ liệu là ",df.shape[0])
print()
print("Số cột của dòng dữ liệu là ",df.shape[1])

#kiểm tra dữ liệu bị thiếu- missing value
df.isna().sum()

"""TỪ KẾT QUẢ TRÊN TA CÓ THỂ THẤY : BỘ DỮ LIỆU CÓ 14 CỘT VÀ 303 DÒNG DỮ LIỆU VÀ TOÀN BỘ LÀ DỮ LIỆU SẠCH

"""

#Thông tin về các cột, các thuộc tính của bộ dư liệu
df.info()
'''Hầu hết tất cả dữ liệu được mã hóa thành số nên các cột dữ liệu toàn bộ là số'''

#Thống kê mô tả cơ bản các thuộc tính
df.describe()

#trực quan dữ liệu để dễ dàng quán sát hơn
#khai báo thư viện
import matplotlib.pyplot as plt
import numpy as np
figure, axis= plt.subplots(3,4,figsize=(20,10))
axis[0,0].hist(df['age'])
axis[0,0].set_title("Histogram age")


axis[0, 1].hist(df['sex'])
axis[0, 1].set_title("Histogram sex")

axis[0, 2].hist(df['cp'])
axis[0, 2].set_title("Histogram cp")

axis[0, 3].hist(df['trestbps'])
axis[0, 3].set_title("Histogram trestbps")

axis[1, 0].hist(df['chol'])
axis[1, 0].set_title("Histogram chol")

axis[1, 1].hist(df['fbs'])
axis[1, 1].set_title("Histogram fbs")

axis[1, 2].hist(df['restecg'])
axis[1, 2].set_title("Histogram restecg")


axis[1, 3].hist(df['thalach'])
axis[1, 3].set_title("Histogram thalach")


axis[2, 0].hist(df['exang'])
axis[2, 0].set_title("Histogram exang")


axis[2, 1].hist(df['oldpeak'])
axis[2, 1].set_title("Histogram oldpeak")


axis[2, 2].hist(df['slope'])
axis[2, 2].set_title("Histogram slope")


axis[2, 3].hist(df['ca'])
axis[2, 3].set_title("Histogram ca")

figure, axis = plt.subplots(1, 2, figsize=(20, 5))
axis[0].hist(df['thal'])
axis[0].set_title("Histogram thal")


axis[1].hist(df['target'])
axis[1].set_title("Histogram target")

# trực quan độ tương quan giữa các cột
import seaborn as sns
figure, axis= plt.subplots(1, 2, figsize=(20,10))
axis[0] = sns.heatmap(df.corr(), annot = True)
axis[0].set_title("Heatmap")
# sns.heatmap(df.corr(), annot =  true)

"""Tiền xử lí dữ liệu và xây dựng mô hình.


*   Như đã nói ở phần đề tài thì cột target là cột cần dự đoán(thuộc tính nhãn) và các cột còn lại là các đặc trưng đầu vào
*   Phần tiền xử lí dữ liệu: là một bộ dữ liệu sạch, phần tìm hiểu dữ liệu  bên trên có thể tháy bộ dữ liệu đã được mã hóa kèm theo đó là không có giá trị thiếu (missing value)


*   Để xây dựng được một mô hình có kết quả tốt cần phải có các bước chuẩn bị tốt. Đối với bài toán dự đoán khả năng mắc bệnh tim( có hoặc không) thì việc cân bằng số nhãn sẽ giúp việc huấn luyện mô hình chính xác hơn, tránh trường hợp bị overfiting. như biểu đồ histogram  vẽ ở phần trên ta có thể thấy 2 nhãn 1 và 0 chênh lệch không nhiều nhưng đảm bảo việc chnhs xác cho mô hình nhóm 13 quyết định dùng kĩ thuật undersampling data- nghĩa là lấy số lượng 2 nhãn bằng nhau.
*   Việc cho hết tất cả các thuộc tính mô tả vào mô hình không phải cách hay.Cách hay nhất nhóm có thể chọn đặc trừng đầu vào có hiệu quả cho mô hình là sử dụng độ tương quan , ở đồ thị heatmap bên trên ta thấy độ tương quan giữa các cột không thực sự cao nên cách này không khả thi.Nhóm 13 quyết định sử dụng kĩ thuật feature selection để chọn lọc các đặc trưng tốt nhất với mục đích tăng độ chính xác của mô hình lên cao nhất có thể.




"""

# cân  bằng dữ liệu
df['target'].value_counts()

# lọc ra 2 giá trị của cột target
df_class_0 = df[df['target']==0]
df_class_1 = df[df['target']==1]

#tiến hành lấy 2 mẫu 1 và 0 đều giống nhau -138
df_class_0_under =  df_class_0.sample(138)
# sau khi lấy mẫu bằng nhau , tiến hành hợp nhất dữ liệu
concat_df = pd.concat([df_class_1,df_class_0_under])
#hiện thị vài dòng dữ liệu để xem kết quả khi  hợp nhất
concat_df.head()

#tiến hành sử dụng kỉ thuật feature seclection để chọn lọc, trích xuất các đặc trưng
# cần lấy ra cột target (thuộc tính nhãn)
labels = concat_df['target']
#lấy ra các thuộc tính mô tả
value =  concat_df[['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal' ]]
# khai báo thư viện
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
#  tiến hành sự dụng kỉ thuật feature seclection
bestfeatures= SelectKBest(score_func=chi2,k='all')
fit =bestfeatures.fit(value,labels)
dfscores =np.array(fit.scores_)
dfcolumns = np.array(value.columns)
#tạo datafram để xem dữ liệu dễ hơn
featureScores = pd.DataFrame({"Feature":dfcolumns,"Score":dfscores})
featureScores['Score'] = featureScores['Score'].apply(lambda x : round(x,2))
featureScores = featureScores.sort_values(['Score'],ascending = False)
featureScores

"""Nhận xét:sau khi feature selection ta có thể thấy các cột :thalach,oldpeak,ca,cp cao hơn các cột còn lại nên nhóm quyết định chọn các cột đó làm dữ liệu đầu vào cho bài toán

# Tiến hành xây  dựng các mô hình:


*   Logitis Regression: Mô hình có hàm kích hoạt là Sigmoid trả ra giá trị 0-1. Đây là 1 mô hình thường được nhắc trong các bài toàn binary classification.

*   DecisionTreeClassifier: Mô hình cây quyết định là một mô hình sử dụng khá là phổ biến và hiệu quả trong cả hai bài toán phân lớp và dự đoán của học có giám sát.Khác với những thuật toán khác học có giám sát,mô hình cây quyết định không tồn tại phương trình dự báo.Mọi việc chúng ta cận thực hiện đó là tìm ra một cây quyết định dự báo tốt trên tập huấn luyện và sự đụng cây quyết định này dự đoán trên tập kiểm tra.
*   RandomForestClassifier: Ở thuật toán Random Forest ta sẽ xây dựng nhiều cây quyết định bằng thuật toán Decision Tree, tuy nhiên mỗi cây quyết định sẽ khác nhau. Sau đó kết quả dự đoán được tổng hợp từ các cây quyết định.


*   KNeighborsClasifier: KNN được cho là thuật toán đơn giản nhất trong máy học. Mô hình xây được xây dựng chỉ bao gồm việc lưu trữ dữ liệu tập huấn(training dataset).Để dự đoán một điểm dữ liệu mới, thuật toán sẽ tìm ra nhưng láng giềng trong dữ liệu tập huấn, đó là láng giềng(nearest neightbors).
"""

#khai báo thư viện
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split

# chia tập dữ liệu thành 2 tập train và test với tỉ lệ 7:3
x = concat_df[['thalach','oldpeak','cp','ca']]
y = concat_df['target']
x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.3,random_state=42)
#để random_state - trộn dữ liệu lên tránh trường hợp overfiting

#train các mô hình
logitis_model = LogisticRegression().fit(x_train, y_train)
de_model = DecisionTreeClassifier().fit(x_train,y_train)
random_model = RandomForestClassifier().fit(x_train,y_train)
knn_model = KNeighborsClassifier().fit(x_train,y_train)

"""# NGHIỆM THU KẾT QUẢ"""

# KHAI BÁO THƯ VIỆN
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

# nghiệm thu kết quả các mô hình trên tập train
#model logitis thông số kỉ thuật

pre_y = logitis_model.predict(x_train)
target_names = ['class 0','class 1']
print(classification_report(y_train,pre_y,target_names=target_names))

cm=confusion_matrix(pre_y, y_train)
sns.heatmap(cm/np.sum(cm),annot=True,fmt=".2%",cmap='Blues')
plt.show();

import sklearn
from sklearn.metrics import accuracy_score
ac=accuracy_score(y_train,pre_y)
print('độ chính xác của logitis là: ',ac*100,'%')

#model decisiontree thông số kĩ thuật
pre_y2=de_model.predict(x_train)
target_names = ['class 0','class 1']
print(classification_report(y_train,pre_y2,target_names=target_names))

cm=confusion_matrix(pre_y2, y_train)
sns.heatmap(cm/np.sum(cm),annot=True,fmt=".2%",cmap='Blues')
plt.show();

import sklearn
from sklearn.metrics import accuracy_score
ac=accuracy_score(y_train,pre_y2)
print('độ chính xác của decision tree là: ',ac*100,'%')

#model random thông số kĩ thuật
pre_y4 = random_model.predict(x_train)
target_names = ['class 0','class 1']
print(classification_report(y_train,pre_y4,target_names=target_names))

#confuse matrix của random model
cm=confusion_matrix(pre_y4, y_train)
sns.heatmap(cm/np.sum(cm),annot=True,fmt=".2%",cmap='Blues')
plt.show();

import sklearn
from sklearn.metrics import accuracy_score
ac=accuracy_score(y_train,pre_y4)
print('độ chính xác của randomforest  là: ',ac*100,'%')

#model knn thông số kĩ thuật
pre_y5=knn_model.predict(x_train)
target_names= ['class 0','class 1']
print(classification_report(y_train,pre_y5,target_names=target_names))

#confuse matrix của knn
cm=confusion_matrix(pre_y5, y_train)
sns.heatmap(cm/np.sum(cm),annot=True,fmt=".2%",cmap='Blues')
plt.show();

import sklearn
from sklearn.metrics import accuracy_score
ac=accuracy_score(y_train,pre_y5)
print('độ chính xác của KNeighbors là: ',ac*100,'%')

"""Nhận xét : đối với tập train các mô hình tương đối cao đặc biệt là decision tree và randomforest có kết quả gần như tuyệt đối

# Sử dụng mô hình đối với tập test và đánh giá kết quả
"""

from mlxtend.plotting import plot_confusion_matrix

#model logitis thông số kĩ thuật trên tập test
pre_test = logitis_model.predict(x_test)
target_names = ['class 0','class 1 ']
print(classification_report(y_test,pre_test,target_names=target_names))

#confuse matrix của logitis model trên tập test
cm=confusion_matrix(pre_test1, y_test)
sns.heatmap(cm/np.sum(cm),annot=True,fmt=".2%",cmap='Blues')
plt.show();

import sklearn
from sklearn.metrics import accuracy_score
ac=accuracy_score(y_test,pre_test1)
print('độ chính xác của logitis là: ',ac*100,'%')

#model de thông số kĩ thuật trên tập test
pre_test2 = de_model.predict(x_test)
target_names = ['class 0','class 1 ']
print(classification_report(y_test,pre_test2,target_names=target_names))

#confuse matrix của de model trên tập test
cm=confusion_matrix(y_test, pre_test2)
sns.heatmap(cm/np.sum(cm),annot=True,fmt=".2%",cmap='Blues')
plt.show();

import sklearn
from sklearn.metrics import accuracy_score
ac=accuracy_score(y_test,pre_test2)
print('độ chính xác của decisiontree là: ',ac*100,'%')

#model random thông số kĩ thuật trên tập test
pre_test3= random_model.predict(x_test)
target_names=['class 0', 'class 1']
print(classification_report(y_test,pre_test3,target_names=target_names))

#confuse matrix của random model trên tập test
cm=confusion_matrix(y_test,pre_test3)
sns.heatmap(cm/np.sum(cm),annot=True,fmt=".2%",cmap='Blues')
plt.show();

import sklearn
from sklearn.metrics import accuracy_score
ac=accuracy_score(y_test,pre_test3)
print('độ chính xác của randomforest là: ',ac*100,'%')

#model knn thông số kĩ thuật trên tập test
pre_test4 = knn_model.predict(x_test)
target_names = ['class 0','class 1 ']
print(classification_report(y_test,pre_test4,target_names=target_names))

#confuse matrix của knn model trên tập test
cm=confusion_matrix(pre_test4, y_test)
sns.heatmap(cm/np.sum(cm),annot=True,fmt=".2%",cmap='Blues')
plt.show();

import sklearn
from sklearn.metrics import accuracy_score
ac=accuracy_score(y_test,pre_test4)
print('độ chính xác của KNeighbors là: ',ac*100,'%')